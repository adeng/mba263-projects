{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell2Cell Group Assignment\n",
    "*Class*: Marketing Analytics (EWMBA263 -1)  \n",
    "*Team*: Albert Deng, Peter Pang, Alex Im, and DJ Prahladka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>calibrat</th>\n",
       "      <th>churn</th>\n",
       "      <th>churndep</th>\n",
       "      <th>revenue</th>\n",
       "      <th>mou</th>\n",
       "      <th>recchrge</th>\n",
       "      <th>directas</th>\n",
       "      <th>overage</th>\n",
       "      <th>roam</th>\n",
       "      <th>...</th>\n",
       "      <th>retaccpt</th>\n",
       "      <th>newcelly</th>\n",
       "      <th>newcelln</th>\n",
       "      <th>refer</th>\n",
       "      <th>incmiss</th>\n",
       "      <th>income</th>\n",
       "      <th>mcycle</th>\n",
       "      <th>setprcm</th>\n",
       "      <th>setprc</th>\n",
       "      <th>retcall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.492500</td>\n",
       "      <td>482.75</td>\n",
       "      <td>37.424999</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149.989990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.275002</td>\n",
       "      <td>1312.25</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.2375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.989998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.662500</td>\n",
       "      <td>25.50</td>\n",
       "      <td>29.990000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.989990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.127499</td>\n",
       "      <td>97.50</td>\n",
       "      <td>65.985001</td>\n",
       "      <td>2.4750</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.989990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.225000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.989990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.515000</td>\n",
       "      <td>1971.50</td>\n",
       "      <td>84.989998</td>\n",
       "      <td>2.2275</td>\n",
       "      <td>249.50</td>\n",
       "      <td>35.497501</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.989990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.564999</td>\n",
       "      <td>270.50</td>\n",
       "      <td>37.480000</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.989990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.590000</td>\n",
       "      <td>153.00</td>\n",
       "      <td>29.990000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199.989990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.270000</td>\n",
       "      <td>1212.75</td>\n",
       "      <td>49.990002</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.285000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.989998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.965000</td>\n",
       "      <td>162.00</td>\n",
       "      <td>69.989998</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.989998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer  calibrat  churn  churndep     revenue      mou   recchrge  \\\n",
       "0   1000002         0      0       NaN   57.492500   482.75  37.424999   \n",
       "1   1000006         0      0       NaN   82.275002  1312.25  75.000000   \n",
       "2   1000010         0      0       NaN   31.662500    25.50  29.990000   \n",
       "3   1000011         0      0       NaN   62.127499    97.50  65.985001   \n",
       "4   1000014         0      0       NaN   25.225000     2.50  25.000000   \n",
       "5   1000015         0      0       NaN  212.515000  1971.50  84.989998   \n",
       "6   1000016         0      0       NaN   42.564999   270.50  37.480000   \n",
       "7   1000018         0      0       NaN   35.590000   153.00  29.990000   \n",
       "8   1000019         0      0       NaN   55.270000  1212.75  49.990002   \n",
       "9   1000020         0      0       NaN   50.965000   162.00  69.989998   \n",
       "\n",
       "   directas  overage       roam  ...  retaccpt  newcelly  newcelln  refer  \\\n",
       "0    0.2475    22.75   0.000000  ...         0         0         1      0   \n",
       "1    1.2375     0.00   0.000000  ...         0         1         0      0   \n",
       "2    0.2475     0.00   0.000000  ...         0         0         1      0   \n",
       "3    2.4750     0.00   0.000000  ...         0         1         0      0   \n",
       "4    0.0000     0.00   0.000000  ...         0         1         0      0   \n",
       "5    2.2275   249.50  35.497501  ...         0         1         0      0   \n",
       "6    0.2475     6.00   0.000000  ...         0         0         1      0   \n",
       "7    0.0000    16.00   0.000000  ...         0         0         1      0   \n",
       "8    0.7425     0.00   1.285000  ...         0         0         1      0   \n",
       "9    0.0000     2.50   0.000000  ...         0         1         0      0   \n",
       "\n",
       "   incmiss  income  mcycle  setprcm      setprc  retcall  \n",
       "0        0       5       0        0  149.989990        0  \n",
       "1        0       6       0        0    9.989998        0  \n",
       "2        0       9       0        0   29.989990        0  \n",
       "3        0       6       0        0   29.989990        0  \n",
       "4        0       7       0        0   29.989990        0  \n",
       "5        0       3       0        0   79.989990        0  \n",
       "6        0       1       0        0   29.989990        0  \n",
       "7        0       4       0        0  199.989990        0  \n",
       "8        0       3       0        0    9.989998        0  \n",
       "9        0       1       0        0    9.989998        0  \n",
       "\n",
       "[10 rows x 70 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import shared.mba263 as mba263\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = pandas.read_csv('shared/cell2cell.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in variable documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>Variable Descriptiion</th>\n",
       "      <th>N</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>Customer ID</td>\n",
       "      <td>71047</td>\n",
       "      <td>1.000001e+06</td>\n",
       "      <td>1099999.00</td>\n",
       "      <td>1.050487e+06</td>\n",
       "      <td>29199.114811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>calibrat</td>\n",
       "      <td>Calibration sample = 1; Validation sample = 0;</td>\n",
       "      <td>71047</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.630076e-01</td>\n",
       "      <td>0.496018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>churn</td>\n",
       "      <td>Churn between 31-60 days after obs_date</td>\n",
       "      <td>71047</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.900756e-01</td>\n",
       "      <td>0.453800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>churndep</td>\n",
       "      <td>Churn (=missing for validation sample)</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>revenue</td>\n",
       "      <td>Mean monthly revenue</td>\n",
       "      <td>70831</td>\n",
       "      <td>-6.167500e+00</td>\n",
       "      <td>1223.38</td>\n",
       "      <td>5.885280e+01</td>\n",
       "      <td>44.243583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Position Variable Name                           Variable Descriptiion  \\\n",
       "0         1      customer                                     Customer ID   \n",
       "1         2      calibrat  Calibration sample = 1; Validation sample = 0;   \n",
       "2         3         churn         Churn between 31-60 days after obs_date   \n",
       "3         4      churndep          Churn (=missing for validation sample)   \n",
       "4         5       revenue                            Mean monthly revenue   \n",
       "\n",
       "       N       Minimum     Maximum          Mean  Standard Deviation  \n",
       "0  71047  1.000001e+06  1099999.00  1.050487e+06        29199.114811  \n",
       "1  71047  0.000000e+00        1.00  5.630076e-01            0.496018  \n",
       "2  71047  0.000000e+00        1.00  2.900756e-01            0.453800  \n",
       "3  40000  0.000000e+00        1.00  5.000000e-01            0.500006  \n",
       "4  70831 -6.167500e+00     1223.38  5.885280e+01           44.243583  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read supplementation documentation and statistics about each variable\n",
    "docs = pandas.read_excel('Cell2Cell_Data_Documentation.xlsx', sheet_name='Sheet1', usecols='A:B,D:I', skiprows=range(0, 5), header=0)\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Selection and Analysis\n",
    "### a) Variable Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_variables(variables):\n",
    "    continuous = []\n",
    "    decile = []\n",
    "    indicator = []\n",
    "\n",
    "    for variable in variables:\n",
    "        if data[variable].max() == 1 and data[variable].min() == 0:\n",
    "            indicator.append(variable)\n",
    "        elif data[variable].max() == 9 and data[variable].min() == 0:\n",
    "            decile.append(variable)\n",
    "        else:\n",
    "            continuous.append(variable)\n",
    "    return continuous, decile, indicator\n",
    "\n",
    "all_variables = ['revenue','mou','recchrge','directas','overage','roam','changem','changer','dropvce','blckvce','unansvce','custcare','threeway','mourec','outcalls','incalls','peakvce','opeakvce','dropblk','callfwdv','callwait','months','uniqsubs','actvsubs','phones','models','eqpdays','age1','age2','children','credita','creditaa','prizmrur','prizmub','prizmtwn','refurb','webcap','truck','rv','occprof','occcler','occcrft','occstud','occhmkr','occret','occself','ownrent','marryun','marryyes','mailord','mailres','mailflag','travel','pcown','creditcd','retcalls','retaccpt','newcelly','newcelln','refer','incmiss','income','mcycle','setprcm','setprc','retcall']\n",
    "\n",
    "# Classify variable types\n",
    "continuous_variables, decile_variables, indicator_variables = classify_variables(all_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Exploratory Data Analysis\n",
    "Define functions to classify whether a variable has a significant difference in predicting churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that checks whether the distribution of a variable is significantly different between two groups\n",
    "def is_indicator_significant(dataset, predict, variable, threshold):\n",
    "    chi2, p = mba263.chi2(dataset[predict], dataset[variable])\n",
    "    # Return whether the p-value is below the threshold\n",
    "    return p < threshold\n",
    "\n",
    "def sort_indicators_by_p(dataset, predict, variables):\n",
    "    p_values = []\n",
    "    for variable in variables:\n",
    "        p = mba263.chi2(dataset[predict], dataset[variable])[1]\n",
    "        p_values.append(p)\n",
    "    return pandas.DataFrame({'variable': variables, 'p': p_values}).sort_values('p')['variable'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['retcall' 'webcap' 'creditaa' 'setprcm' 'refurb' 'mailres' 'mailord'\n",
      " 'marryun' 'credita' 'incmiss' 'ownrent' 'creditcd' 'newcelly' 'prizmtwn']\n"
     ]
    }
   ],
   "source": [
    "test = data.loc[data['calibrat'] == 1]\n",
    "\n",
    "# Filter the indicator_variables list to only include significant variables\n",
    "sig_indicator_variables = [variable for variable in indicator_variables \n",
    "                           if is_indicator_significant(test, 'churndep', variable, 0.03)]\n",
    "sig_indicator_variables = sort_indicators_by_p(test, 'churndep', sig_indicator_variables)\n",
    "print(sig_indicator_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newcelly\n",
       "0    0.503315\n",
       "1    0.486147\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('newcelly')['churn'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append sig_indicator_variables, decile_variables, and continuous variables together\n",
    "selected_variables = np.concatenate((sig_indicator_variables, decile_variables, continuous_variables), axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run analyses\n",
    "### a) Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that will tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.67154408662935\n",
      "            Iterations: 768\n",
      "            Function evaluations: 824\n",
      "            Gradient evaluations: 768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "churndep\n",
       "0    0.014334\n",
       "1    0.027762\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = data.copy()\n",
    "tr, te = data[data['calibrat'] == 1], data[data['calibrat'] == 0]\n",
    "\n",
    "mod = mba263.logit_reg(tr['churndep'], tr[all_variables], 0.1)\n",
    "tr['pred'] = mod.predict(tr[all_variables])\n",
    "tr['churndep'] = np.where(tr['pred'] > 0.5, 1, 0)\n",
    "\n",
    "te['pred'] = mod.predict(te[all_variables])\n",
    "te['churndep'] = np.where(te['pred'] > 0.5, 1, 0)\n",
    "\n",
    "# (te.loc[te['churndep'] == 1]['churn'].mean() / te['churn'].mean()) * 100\n",
    "# tr[['pred', 'churn', 'churndep']].head()\n",
    "te.groupby('churndep')['churn'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create a custom scoring function based on lift calculations\n",
    "def exp_churn_scoring(test_set, predict, actual):\n",
    "   test_set['pred'] = predict\n",
    "   pred_rate = test_set.loc[test_set['pred'] == 1]['churn'].mean()\n",
    "   actual_rate = np.mean(actual)\n",
    "   return (pred_rate / actual_rate)*100\n",
    "    \n",
    "# A function to identify the best parameter(s) for a model tested using cross-validation\n",
    "def tune_hyperparameters(train_dataset, predict, variables, threshold, param_grid, mod_type):\n",
    "   # Set up the KFold object\n",
    "   kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "   best_score = -np.inf\n",
    "   \n",
    "   # Loop over the parameter grid for logistic regressions and neural networks\n",
    "   if mod_type == 'logit_reg' or mod_type == 'neural_network':\n",
    "      for a in param_grid['a']:\n",
    "         scores = []\n",
    "         \n",
    "         # Loop over the cross-validation folds\n",
    "         for train_index, test_index in kf.split(train_dataset):\n",
    "\n",
    "            # Split the dataset\n",
    "            x_train, x_test = train_dataset.iloc[train_index][variables], train_dataset.iloc[test_index][variables]\n",
    "            y_train, y_test = train_dataset.iloc[train_index][predict], train_dataset.iloc[test_index][predict]\n",
    "\n",
    "            # Fit and run the model\n",
    "            if mod_type == 'logit_reg':\n",
    "               model = mba263.logit_reg(y_train, x_train, a)\n",
    "            elif mod_type == 'neural_network':\n",
    "               model = mba263.neural_network(y_train, x_train, a)\n",
    "               \n",
    "            # Score results\n",
    "            y_pred = np.where(model.predict(x_test) > threshold, 1, 0)\n",
    "            scores.append(exp_churn_scoring(train_dataset.iloc[test_index], y_pred, y_test))\n",
    "\n",
    "         # Compute the average score\n",
    "         mean_score = np.mean(scores)\n",
    "\n",
    "         # If the score is better, record the parameter\n",
    "         if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_param = {'a': a}\n",
    "         \n",
    "         # Reset scores\n",
    "         scores.clear()\n",
    "\n",
    "   # Return the best parameter\n",
    "   return best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A function to run a logistic regression, a logistic regression w/ regularization, \n",
    "### a neural network, and a random forest\n",
    "### Function adds two columns, p for probability and res if selected for targeting\n",
    "def run_ml_models(dataset, actual, variables, threshold):\n",
    "    df = dataset.copy()\n",
    "\n",
    "    # Split dataset into train and test based on whether calibrat = 0 or 1\n",
    "    train, test = data[data['calibrat'] == 1], data[data['calibrat'] == 0]\n",
    "\n",
    "    ### Use a logistic regression with regularization\n",
    "    ### ------------------------------------------------\n",
    "    logit_reg_param_grid = {'a': [0, 0.01, 0.1, 0.5, 1, 3]}\n",
    "    best_param_logit_reg = tune_hyperparameters(\n",
    "        train, actual, variables, threshold, logit_reg_param_grid, 'logit_reg')\n",
    "\n",
    "    # Use the tuned parameter to predict\n",
    "    result_logit_reg = mba263.logit_reg(train[actual], train[variables], best_param_logit_reg['a'])\n",
    "    train['p_logr'] = result_logit_reg.predict(train[variables])\n",
    "    train['res_logr'] = np.where(train['p_logr'] > threshold, 1, 0)\n",
    "    test['p_logr'] = result_logit_reg.predict(test[variables])\n",
    "    test['res_logr'] = np.where(test['p_logr'] > threshold, 1, 0)\n",
    "\n",
    "    # Rename churn to actuals\n",
    "    train['actual_res'] = train['churn']\n",
    "    test['actual_res'] = test['churn']\n",
    "\n",
    "    # Return three items, the results on the test dataset, the results on the training, and the models\n",
    "    return [test[['customer', 'p_logr','actual_res', 'res_logr',]],\n",
    "            train[['customer', 'p_logr','actual_res', 'res_logr',]], \n",
    "               [result_logit_reg],\n",
    "               [best_param_logit_reg]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune and run the logistic regression based on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6720984088802252\n",
      "            Iterations: 201\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 201\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6720358673745008\n",
      "            Iterations: 206\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 206\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.671394035530198\n",
      "            Iterations: 200\n",
      "            Function evaluations: 257\n",
      "            Gradient evaluations: 200\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6701892406260681\n",
      "            Iterations: 215\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 215\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6709702527417803\n",
      "            Iterations: 205\n",
      "            Function evaluations: 260\n",
      "            Gradient evaluations: 205\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6721001454355127\n",
      "            Iterations: 569\n",
      "            Function evaluations: 624\n",
      "            Gradient evaluations: 569\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6720374947130028\n",
      "            Iterations: 615\n",
      "            Function evaluations: 670\n",
      "            Gradient evaluations: 615\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6713957508272035\n",
      "            Iterations: 660\n",
      "            Function evaluations: 716\n",
      "            Gradient evaluations: 660\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6701912102539542\n",
      "            Iterations: 551\n",
      "            Function evaluations: 607\n",
      "            Gradient evaluations: 551\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6709719769068975\n",
      "            Iterations: 587\n",
      "            Function evaluations: 643\n",
      "            Gradient evaluations: 587\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6721121241217224\n",
      "            Iterations: 749\n",
      "            Function evaluations: 804\n",
      "            Gradient evaluations: 749\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6720496737199096\n",
      "            Iterations: 586\n",
      "            Function evaluations: 642\n",
      "            Gradient evaluations: 586\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6714088047186524\n",
      "            Iterations: 713\n",
      "            Function evaluations: 770\n",
      "            Gradient evaluations: 713\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6702047642241761\n",
      "            Iterations: 701\n",
      "            Function evaluations: 757\n",
      "            Gradient evaluations: 701\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6709844514745427\n",
      "            Iterations: 698\n",
      "            Function evaluations: 754\n",
      "            Gradient evaluations: 698\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6721663349875715\n",
      "            Iterations: 372\n",
      "            Function evaluations: 426\n",
      "            Gradient evaluations: 372\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6721042425652312\n",
      "            Iterations: 344\n",
      "            Function evaluations: 400\n",
      "            Gradient evaluations: 344\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6714666263384728\n",
      "            Iterations: 383\n",
      "            Function evaluations: 439\n",
      "            Gradient evaluations: 383\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6702661566362287\n",
      "            Iterations: 376\n",
      "            Function evaluations: 431\n",
      "            Gradient evaluations: 376\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.671040328031439\n",
      "            Iterations: 377\n",
      "            Function evaluations: 432\n",
      "            Gradient evaluations: 377\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6722326620458479\n",
      "            Iterations: 311\n",
      "            Function evaluations: 366\n",
      "            Gradient evaluations: 311\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6721709664357389\n",
      "            Iterations: 288\n",
      "            Function evaluations: 344\n",
      "            Gradient evaluations: 288\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6715362963476187\n",
      "            Iterations: 308\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 308\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6703413702983367\n",
      "            Iterations: 310\n",
      "            Function evaluations: 366\n",
      "            Gradient evaluations: 310\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6711085143634755\n",
      "            Iterations: 285\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 285\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6724826004853409\n",
      "            Iterations: 265\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 265\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6724228008349543\n",
      "            Iterations: 258\n",
      "            Function evaluations: 313\n",
      "            Gradient evaluations: 258\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6717947114235746\n",
      "            Iterations: 222\n",
      "            Function evaluations: 278\n",
      "            Gradient evaluations: 222\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6706256174533378\n",
      "            Iterations: 256\n",
      "            Function evaluations: 312\n",
      "            Gradient evaluations: 256\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6713630667070083\n",
      "            Iterations: 224\n",
      "            Function evaluations: 280\n",
      "            Gradient evaluations: 224\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.67154408662935\n",
      "            Iterations: 768\n",
      "            Function evaluations: 824\n",
      "            Gradient evaluations: 768\n"
     ]
    }
   ],
   "source": [
    "predictions, actuals, model, params = run_ml_models(data, \"churndep\", all_variables, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation\n",
    "### a) Evaluate model characteristics\n",
    "Print parameters, coefficients, and odds for the resulting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Regularization Parameter: 0.1\n",
      "Logistic Regression w/ Regularization Coefficients\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Mba263Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>churndep</td>     <th>  No. Observations:  </th>   <td> 38941</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>              <td>Mba263Logit</td>   <th>  Df Residuals:      </th>   <td> 38875</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    65</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 02 Apr 2024</td> <th>  Pseudo R-squ.:     </th>   <td>0.03117</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>08:59:44</td>     <th>  Log-Likelihood:    </th>  <td> -26150.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -26992.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.178e-308</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    0.1485</td> <td>    0.095</td> <td>    1.559</td> <td> 0.119</td> <td>   -0.038</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>revenue</th>  <td>    0.0020</td> <td>    0.001</td> <td>    2.460</td> <td> 0.014</td> <td>    0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mou</th>      <td>   -0.0003</td> <td> 4.96e-05</td> <td>   -5.657</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recchrge</th> <td>   -0.0031</td> <td>    0.001</td> <td>   -3.512</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>directas</th> <td>   -0.0012</td> <td>    0.006</td> <td>   -0.202</td> <td> 0.840</td> <td>   -0.013</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overage</th>  <td>    0.0008</td> <td>    0.000</td> <td>    2.712</td> <td> 0.007</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam</th>     <td>    0.0071</td> <td>    0.002</td> <td>    3.436</td> <td> 0.001</td> <td>    0.003</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>changem</th>  <td>   -0.0005</td> <td> 5.35e-05</td> <td>   -9.194</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>changer</th>  <td>    0.0023</td> <td>    0.000</td> <td>    6.247</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dropvce</th>  <td>    0.0113</td> <td>    0.007</td> <td>    1.561</td> <td> 0.119</td> <td>   -0.003</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blckvce</th>  <td>    0.0064</td> <td>    0.007</td> <td>    0.892</td> <td> 0.372</td> <td>   -0.008</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unansvce</th> <td>    0.0009</td> <td>    0.000</td> <td>    2.058</td> <td> 0.040</td> <td> 4.41e-05</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>custcare</th> <td>   -0.0060</td> <td>    0.003</td> <td>   -2.331</td> <td> 0.020</td> <td>   -0.011</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>threeway</th> <td>   -0.0303</td> <td>    0.011</td> <td>   -2.690</td> <td> 0.007</td> <td>   -0.052</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mourec</th>   <td>    0.0001</td> <td>    0.000</td> <td>    1.017</td> <td> 0.309</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>outcalls</th> <td>    0.0011</td> <td>    0.001</td> <td>    1.894</td> <td> 0.058</td> <td>-3.89e-05</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>incalls</th>  <td>   -0.0031</td> <td>    0.001</td> <td>   -2.937</td> <td> 0.003</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peakvce</th>  <td>   -0.0007</td> <td>    0.000</td> <td>   -3.058</td> <td> 0.002</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>opeakvce</th> <td>   -0.0002</td> <td>    0.000</td> <td>   -0.782</td> <td> 0.434</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dropblk</th>  <td>   -0.0031</td> <td>    0.007</td> <td>   -0.440</td> <td> 0.660</td> <td>   -0.017</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>callfwdv</th> <td>   -0.0026</td> <td>    0.023</td> <td>   -0.111</td> <td> 0.912</td> <td>   -0.048</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>callwait</th> <td>    0.0021</td> <td>    0.003</td> <td>    0.662</td> <td> 0.508</td> <td>   -0.004</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>months</th>   <td>   -0.0213</td> <td>    0.002</td> <td>  -10.648</td> <td> 0.000</td> <td>   -0.025</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>uniqsubs</th> <td>    0.1843</td> <td>    0.020</td> <td>    9.223</td> <td> 0.000</td> <td>    0.145</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>actvsubs</th> <td>   -0.2056</td> <td>    0.028</td> <td>   -7.367</td> <td> 0.000</td> <td>   -0.260</td> <td>   -0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>phones</th>   <td>    0.0487</td> <td>    0.018</td> <td>    2.680</td> <td> 0.007</td> <td>    0.013</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>models</th>   <td>    0.0138</td> <td>    0.028</td> <td>    0.495</td> <td> 0.621</td> <td>   -0.041</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eqpdays</th>  <td>    0.0014</td> <td> 7.47e-05</td> <td>   19.310</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age1</th>     <td>   -0.0033</td> <td>    0.001</td> <td>   -3.784</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age2</th>     <td>   -0.0012</td> <td>    0.001</td> <td>   -1.719</td> <td> 0.086</td> <td>   -0.003</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>children</th> <td>    0.0946</td> <td>    0.028</td> <td>    3.362</td> <td> 0.001</td> <td>    0.039</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>credita</th>  <td>   -0.1778</td> <td>    0.036</td> <td>   -5.008</td> <td> 0.000</td> <td>   -0.247</td> <td>   -0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>creditaa</th> <td>   -0.3624</td> <td>    0.035</td> <td>  -10.482</td> <td> 0.000</td> <td>   -0.430</td> <td>   -0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prizmrur</th> <td>    0.0664</td> <td>    0.050</td> <td>    1.340</td> <td> 0.180</td> <td>   -0.031</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prizmub</th>  <td>   -0.0396</td> <td>    0.024</td> <td>   -1.623</td> <td> 0.105</td> <td>   -0.087</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prizmtwn</th> <td>    0.0462</td> <td>    0.031</td> <td>    1.469</td> <td> 0.142</td> <td>   -0.015</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>refurb</th>   <td>    0.2340</td> <td>    0.032</td> <td>    7.322</td> <td> 0.000</td> <td>    0.171</td> <td>    0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>webcap</th>   <td>   -0.1558</td> <td>    0.038</td> <td>   -4.148</td> <td> 0.000</td> <td>   -0.229</td> <td>   -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>truck</th>    <td>    0.0268</td> <td>    0.036</td> <td>    0.745</td> <td> 0.456</td> <td>   -0.044</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rv</th>       <td>    0.0119</td> <td>    0.048</td> <td>    0.248</td> <td> 0.804</td> <td>   -0.082</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occprof</th>  <td>   -0.0198</td> <td>    0.033</td> <td>   -0.609</td> <td> 0.542</td> <td>   -0.083</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occcler</th>  <td>    0.0393</td> <td>    0.075</td> <td>    0.524</td> <td> 0.600</td> <td>   -0.108</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occcrft</th>  <td>   -0.0196</td> <td>    0.063</td> <td>   -0.312</td> <td> 0.755</td> <td>   -0.143</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occstud</th>  <td>    0.1189</td> <td>    0.122</td> <td>    0.976</td> <td> 0.329</td> <td>   -0.120</td> <td>    0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occhmkr</th>  <td>    0.2503</td> <td>    0.190</td> <td>    1.317</td> <td> 0.188</td> <td>   -0.122</td> <td>    0.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occret</th>   <td>   -0.0396</td> <td>    0.091</td> <td>   -0.438</td> <td> 0.662</td> <td>   -0.217</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occself</th>  <td>   -0.0699</td> <td>    0.081</td> <td>   -0.868</td> <td> 0.386</td> <td>   -0.228</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ownrent</th>  <td>    0.0024</td> <td>    0.043</td> <td>    0.055</td> <td> 0.956</td> <td>   -0.081</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>marryun</th>  <td>    0.1087</td> <td>    0.034</td> <td>    3.194</td> <td> 0.001</td> <td>    0.042</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>marryyes</th> <td>    0.0555</td> <td>    0.032</td> <td>    1.709</td> <td> 0.087</td> <td>   -0.008</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mailord</th>  <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mailres</th>  <td>   -0.1289</td> <td>    0.028</td> <td>   -4.558</td> <td> 0.000</td> <td>   -0.184</td> <td>   -0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mailflag</th> <td>   -0.0475</td> <td>    0.084</td> <td>   -0.563</td> <td> 0.573</td> <td>   -0.213</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>travel</th>   <td>   -0.0005</td> <td>    0.047</td> <td>   -0.011</td> <td> 0.991</td> <td>   -0.093</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pcown</th>    <td>    0.0340</td> <td>    0.031</td> <td>    1.097</td> <td> 0.273</td> <td>   -0.027</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>creditcd</th> <td>    0.0421</td> <td>    0.044</td> <td>    0.963</td> <td> 0.335</td> <td>   -0.044</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>retcalls</th> <td>    0.0102</td> <td>    0.184</td> <td>    0.055</td> <td> 0.956</td> <td>   -0.350</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>retaccpt</th> <td>   -0.1258</td> <td>    0.108</td> <td>   -1.168</td> <td> 0.243</td> <td>   -0.337</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newcelly</th> <td>   -0.0705</td> <td>    0.027</td> <td>   -2.585</td> <td> 0.010</td> <td>   -0.124</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newcelln</th> <td>   -0.0051</td> <td>    0.032</td> <td>   -0.162</td> <td> 0.871</td> <td>   -0.067</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>refer</th>    <td>   -0.0499</td> <td>    0.042</td> <td>   -1.184</td> <td> 0.237</td> <td>   -0.132</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>incmiss</th>  <td>   -0.0908</td> <td>    0.060</td> <td>   -1.513</td> <td> 0.130</td> <td>   -0.209</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>   <td>   -0.0132</td> <td>    0.006</td> <td>   -2.190</td> <td> 0.029</td> <td>   -0.025</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mcycle</th>   <td>    0.1212</td> <td>    0.089</td> <td>    1.362</td> <td> 0.173</td> <td>   -0.053</td> <td>    0.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>setprcm</th>  <td>   -0.0961</td> <td>    0.041</td> <td>   -2.371</td> <td> 0.018</td> <td>   -0.175</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>setprc</th>   <td>    0.0006</td> <td>    0.000</td> <td>    2.198</td> <td> 0.028</td> <td> 6.74e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>retcall</th>  <td>    0.7943</td> <td>    0.195</td> <td>    4.083</td> <td> 0.000</td> <td>    0.413</td> <td>    1.176</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                        Mba263Logit Regression Results                        \n",
       "==============================================================================\n",
       "Dep. Variable:               churndep   No. Observations:                38941\n",
       "Model:                    Mba263Logit   Df Residuals:                    38875\n",
       "Method:                           MLE   Df Model:                           65\n",
       "Date:                Tue, 02 Apr 2024   Pseudo R-squ.:                 0.03117\n",
       "Time:                        08:59:44   Log-Likelihood:                -26150.\n",
       "converged:                       True   LL-Null:                       -26992.\n",
       "Covariance Type:            nonrobust   LLR p-value:                1.178e-308\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.1485      0.095      1.559      0.119      -0.038       0.335\n",
       "revenue        0.0020      0.001      2.460      0.014       0.000       0.004\n",
       "mou           -0.0003   4.96e-05     -5.657      0.000      -0.000      -0.000\n",
       "recchrge      -0.0031      0.001     -3.512      0.000      -0.005      -0.001\n",
       "directas      -0.0012      0.006     -0.202      0.840      -0.013       0.010\n",
       "overage        0.0008      0.000      2.712      0.007       0.000       0.001\n",
       "roam           0.0071      0.002      3.436      0.001       0.003       0.011\n",
       "changem       -0.0005   5.35e-05     -9.194      0.000      -0.001      -0.000\n",
       "changer        0.0023      0.000      6.247      0.000       0.002       0.003\n",
       "dropvce        0.0113      0.007      1.561      0.119      -0.003       0.026\n",
       "blckvce        0.0064      0.007      0.892      0.372      -0.008       0.020\n",
       "unansvce       0.0009      0.000      2.058      0.040    4.41e-05       0.002\n",
       "custcare      -0.0060      0.003     -2.331      0.020      -0.011      -0.001\n",
       "threeway      -0.0303      0.011     -2.690      0.007      -0.052      -0.008\n",
       "mourec         0.0001      0.000      1.017      0.309      -0.000       0.000\n",
       "outcalls       0.0011      0.001      1.894      0.058   -3.89e-05       0.002\n",
       "incalls       -0.0031      0.001     -2.937      0.003      -0.005      -0.001\n",
       "peakvce       -0.0007      0.000     -3.058      0.002      -0.001      -0.000\n",
       "opeakvce      -0.0002      0.000     -0.782      0.434      -0.001       0.000\n",
       "dropblk       -0.0031      0.007     -0.440      0.660      -0.017       0.011\n",
       "callfwdv      -0.0026      0.023     -0.111      0.912      -0.048       0.043\n",
       "callwait       0.0021      0.003      0.662      0.508      -0.004       0.008\n",
       "months        -0.0213      0.002    -10.648      0.000      -0.025      -0.017\n",
       "uniqsubs       0.1843      0.020      9.223      0.000       0.145       0.224\n",
       "actvsubs      -0.2056      0.028     -7.367      0.000      -0.260      -0.151\n",
       "phones         0.0487      0.018      2.680      0.007       0.013       0.084\n",
       "models         0.0138      0.028      0.495      0.621      -0.041       0.068\n",
       "eqpdays        0.0014   7.47e-05     19.310      0.000       0.001       0.002\n",
       "age1          -0.0033      0.001     -3.784      0.000      -0.005      -0.002\n",
       "age2          -0.0012      0.001     -1.719      0.086      -0.003       0.000\n",
       "children       0.0946      0.028      3.362      0.001       0.039       0.150\n",
       "credita       -0.1778      0.036     -5.008      0.000      -0.247      -0.108\n",
       "creditaa      -0.3624      0.035    -10.482      0.000      -0.430      -0.295\n",
       "prizmrur       0.0664      0.050      1.340      0.180      -0.031       0.164\n",
       "prizmub       -0.0396      0.024     -1.623      0.105      -0.087       0.008\n",
       "prizmtwn       0.0462      0.031      1.469      0.142      -0.015       0.108\n",
       "refurb         0.2340      0.032      7.322      0.000       0.171       0.297\n",
       "webcap        -0.1558      0.038     -4.148      0.000      -0.229      -0.082\n",
       "truck          0.0268      0.036      0.745      0.456      -0.044       0.097\n",
       "rv             0.0119      0.048      0.248      0.804      -0.082       0.106\n",
       "occprof       -0.0198      0.033     -0.609      0.542      -0.083       0.044\n",
       "occcler        0.0393      0.075      0.524      0.600      -0.108       0.186\n",
       "occcrft       -0.0196      0.063     -0.312      0.755      -0.143       0.104\n",
       "occstud        0.1189      0.122      0.976      0.329      -0.120       0.358\n",
       "occhmkr        0.2503      0.190      1.317      0.188      -0.122       0.623\n",
       "occret        -0.0396      0.091     -0.438      0.662      -0.217       0.138\n",
       "occself       -0.0699      0.081     -0.868      0.386      -0.228       0.088\n",
       "ownrent        0.0024      0.043      0.055      0.956      -0.081       0.086\n",
       "marryun        0.1087      0.034      3.194      0.001       0.042       0.175\n",
       "marryyes       0.0555      0.032      1.709      0.087      -0.008       0.119\n",
       "mailord             0        nan        nan        nan         nan         nan\n",
       "mailres       -0.1289      0.028     -4.558      0.000      -0.184      -0.073\n",
       "mailflag      -0.0475      0.084     -0.563      0.573      -0.213       0.118\n",
       "travel        -0.0005      0.047     -0.011      0.991      -0.093       0.092\n",
       "pcown          0.0340      0.031      1.097      0.273      -0.027       0.095\n",
       "creditcd       0.0421      0.044      0.963      0.335      -0.044       0.128\n",
       "retcalls       0.0102      0.184      0.055      0.956      -0.350       0.370\n",
       "retaccpt      -0.1258      0.108     -1.168      0.243      -0.337       0.085\n",
       "newcelly      -0.0705      0.027     -2.585      0.010      -0.124      -0.017\n",
       "newcelln      -0.0051      0.032     -0.162      0.871      -0.067       0.057\n",
       "refer         -0.0499      0.042     -1.184      0.237      -0.132       0.033\n",
       "incmiss       -0.0908      0.060     -1.513      0.130      -0.209       0.027\n",
       "income        -0.0132      0.006     -2.190      0.029      -0.025      -0.001\n",
       "mcycle         0.1212      0.089      1.362      0.173      -0.053       0.296\n",
       "setprcm       -0.0961      0.041     -2.371      0.018      -0.175      -0.017\n",
       "setprc         0.0006      0.000      2.198      0.028    6.74e-05       0.001\n",
       "retcall        0.7943      0.195      4.083      0.000       0.413       1.176\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression w/ Regularization Odds Ratios\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Odds ratios</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>1.001965</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>2.457604</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1.000414</td>\n",
       "      <td>1.003517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mou</th>\n",
       "      <td>0.999719</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>5.657802</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>0.999815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recchrge</th>\n",
       "      <td>0.996883</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>3.517850</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.995164</td>\n",
       "      <td>0.998602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>directas</th>\n",
       "      <td>0.998801</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.202114</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.987294</td>\n",
       "      <td>1.010308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overage</th>\n",
       "      <td>1.000761</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>2.710596</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000216</td>\n",
       "      <td>1.001305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0.986876</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>2.204375</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.975327</td>\n",
       "      <td>0.998426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcycle</th>\n",
       "      <td>1.128885</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>1.283121</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.934019</td>\n",
       "      <td>1.323751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setprcm</th>\n",
       "      <td>0.908404</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>2.488900</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.837008</td>\n",
       "      <td>0.979799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setprc</th>\n",
       "      <td>1.000622</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>2.197798</td>\n",
       "      <td>0.028</td>\n",
       "      <td>1.000073</td>\n",
       "      <td>1.001171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retcall</th>\n",
       "      <td>2.212866</td>\n",
       "      <td>0.430517</td>\n",
       "      <td>2.817234</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.377664</td>\n",
       "      <td>3.048069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Odds ratios   std err         z  P>|z|    [0.025    0.975]\n",
       "revenue      1.001965  0.000800  2.457604  0.014  1.000414  1.003517\n",
       "mou          0.999719  0.000050  5.657802  0.000  0.999623  0.999815\n",
       "recchrge     0.996883  0.000886  3.517850  0.000  0.995164  0.998602\n",
       "directas     0.998801  0.005931  0.202114  0.840  0.987294  1.010308\n",
       "overage      1.000761  0.000281  2.710596  0.007  1.000216  1.001305\n",
       "...               ...       ...       ...    ...       ...       ...\n",
       "income       0.986876  0.005953  2.204375  0.027  0.975327  0.998426\n",
       "mcycle       1.128885  0.100446  1.283121  0.199  0.934019  1.323751\n",
       "setprcm      0.908404  0.036802  2.488900  0.013  0.837008  0.979799\n",
       "setprc       1.000622  0.000283  2.197798  0.028  1.000073  1.001171\n",
       "retcall      2.212866  0.430517  2.817234  0.005  1.377664  3.048069\n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "def print_params(params):\n",
    "    print(\"Logistic Regression Regularization Parameter: {}\".format(params[0]['a']))\n",
    "\n",
    "# Print the coefficients for the logistic regressions\n",
    "def print_coefs(models):\n",
    "    print(\"Logistic Regression w/ Regularization Coefficients\")\n",
    "    display(models[0].summary())\n",
    "\n",
    "# Print the odds ratios for each logistic regression\n",
    "def print_odds(models):\n",
    "    print(\"Logistic Regression w/ Regularization Odds Ratios\")\n",
    "    display(mba263.odds_ratios(models[0]))\n",
    "\n",
    "print_params(params)\n",
    "print_coefs(model)\n",
    "print_odds(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Analyze Lift\n",
    "Calculate overall model lift based on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lift: 141.53%\n"
     ]
    }
   ],
   "source": [
    "test_rate = predictions['actual_res'].mean()\n",
    "selected_test_rate = predictions.loc[predictions['res_logr'] == 1]['actual_res'].mean()\n",
    "print(\"Lift: {:.2f}%\".format((selected_test_rate / test_rate) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate lift by deciles and construct a lift chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2079b28a910>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mba263.lift(predictions['actual_res'], predictions['p_logr']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
